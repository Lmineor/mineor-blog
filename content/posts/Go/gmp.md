---
title: "GMP"
date: 2023-11-12
draft: true
tags : [                    # 文章所属标签
    "Go", 
]
---

非原创

> 好文：https://yizhi.ren/2019/06/03/goscheduler

> 参考：https://blog.csdn.net/xmcy001122/article/details/119392934

# Go 语言的协程 goroutine

Go 为了提供更容易使用的并发方法，使用了 goroutine 和 channel。goroutine 来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被 runtime 调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。

Go 中，协程被称为 goroutine，它非常轻量，一个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。虽然一个 goroutine 的栈只占几 KB，但实际是可伸缩的，如果需要更多内容，runtime 会自动为 goroutine 分配。

# GMP核心组件

GMP模型由三个核心部分组成

- G(Goroutine)：用户级的轻量级协程，存储执行栈、程序计数器（PC）和状态信息。
- M(Machine)：操作系统线程（OS Thread）的抽象，由操作系统直接调度，负责执行G的代码
- 

Go 的 **GMP 模型**（Goroutine-M-Processor）是 Go 语言实现高并发的核心调度机制，它通过用户态的轻量级调度器管理 Goroutine，并高效复用操作系统的线程（Thread）。以下是详细解析，帮助你理解其工作原理。

---

### **1. GMP 核心组件**
GMP 模型由三个核心部分组成：
- **G（Goroutine）**：用户级的轻量级协程，存储执行栈、程序计数器（PC）和状态信息。
- **M（Machine）**：操作系统线程（OS Thread）的抽象，由操作系统直接调度，负责执行 G 的代码。
- **P（Processor）**：逻辑处理器，是 G 和 M 之间的协调者，每个 P 维护一个本地 Goroutine 队列（Local Queue）。

<a class="out-link" href="http://ai.h3c.com/redirect?target=(https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fgeorge-wang-cy%2Fstatic-images%2Fgo-gmp-model.png)" title="外部资源链接" target="_blank">(https://cdn.jsdelivr.net/gh/george-wang-cy/static-images/go-gmp-model.png)</a>

---

### **2. GMP 调度器的设计目标**
- **高并发**：支持百万级 Goroutine 并发。
- **低延迟**：减少 Goroutine 切换和调度的开销。
- **资源高效**：避免频繁创建/销毁线程，复用系统资源。

---

### **3. GMP 调度机制详解**

#### **(1) **P（Processor）的作用**
- P 是 Go 调度器的核心，**决定并发执行的并行度**（通过 `GOMAXPROCS` 设置 P 的数量，默认等于 CPU 核数）。
- 每个 P 维护一个**本地运行队列（Local Queue）**，用于存放待执行的 Goroutine。
- P 还负责管理一些关键资源（如网络轮询器、计时器等）。

#### **(2) M（Machine）与线程绑定**
- M 是操作系统线程的抽象，必须绑定一个 P 才能执行 G。
- 如果 M 在执行 G 时发生阻塞（如系统调用），会释放绑定的 P，让其他 M 接管 P 继续执行其他 G。

#### **(3) Goroutine 的调度流程**
1. **创建 G**：当启动一个 Goroutine（`go func()`）时：
   - G 会被放入当前 P 的本地队列。
   - 如果本地队列已满，则放入全局队列（Global Queue）。

2. **M 获取 G**：
   - M 优先从绑定的 P 的本地队列获取 G。
   - 如果本地队列为空，M 会尝试从全局队列窃取 G。
   - 如果全局队列也为空，M 会从其他 P 的本地队列“偷取”（Work Stealing）一半的 G。

3. **执行 G**：
   - M 执行 G 的代码，直到 G 主动让出 CPU（如遇到 `channel` 阻塞、`time.Sleep` 等）。
   - 当 G 阻塞时，M 会释放 P，进入休眠状态，等待被唤醒。

4. **系统调用处理**：
   - 如果 G 执行了阻塞式系统调用（如文件 I/O），Go 调度器会将 M 和 G 分离，并创建新的 M 接管 P 继续执行其他 G。
   - 当系统调用返回，G 会被重新放入队列，M 则进入休眠或销毁。

---

### **4. 关键调度策略**

#### **(1) 工作窃取（Work Stealing）**
- 当 P 的本地队列为空时，会优先从全局队列获取 G，若全局队列也为空，则从其他 P 的本地队列窃取一半的 G。
- **目的**：平衡各 P 的工作负载，避免“饥饿”。

#### **(2) 抢占式调度（Preemption）**
- Go 1.14 之前，Goroutine 只能通过函数调用（如 `channel` 操作）主动让出 CPU。
- Go 1.14+ 引入了**基于信号的抢占式调度**，避免长时间运行的 Goroutine 阻塞其他任务。

#### **(3) 自旋线程（Spinning Thread）**
- 当 M 找不到可执行的 G 时，会短暂进入“自旋”状态（不释放 CPU），等待新的 G 加入队列。
- **目的**：减少线程频繁休眠和唤醒的开销。

---

### **5. GMP 的运行示例**

#### **场景 1：Goroutine 正常执行**
1. 启动 4 个 P（假设 `GOMAXPROCS=4`），每个 P 绑定一个 M。
2. 创建 1000 个 G，大部分进入各 P 的本地队列。
3. 每个 M 从自己的 P 队列获取 G 并执行。

#### **场景 2：Goroutine 阻塞**
1. 某个 G 执行 `time.Sleep`，主动让出 CPU。
2. M 将 G 放入“等待队列”，并继续执行其他 G。

#### **场景 3：系统调用阻塞**
1. 某个 G 执行阻塞式系统调用（如 `http.Get`）。
2. M 会释放 P，由其他 M 接管 P 继续执行。
3. 当系统调用完成，G 会被重新放入队列等待执行。

---

### **6. 为什么需要 P（Processor）？**
- **解耦 M 和 G**：避免 M 直接管理 G，减少锁竞争。
- **资源控制**：通过 `GOMAXPROCS` 限制并行度，防止过度消耗 CPU。
- **本地队列**：每个 P 维护本地队列，减少全局队列的锁争用。

---

### **7. 可视化模型：餐厅比喻**
- **G（顾客）**：需要被服务的请求。
- **M（服务员）**：实际处理请求的人。
- **P（餐台）**：服务员的工作台，存放待处理的订单（本地队列）。
  - 服务员（M）从自己的餐台（P）优先取订单（G）。
  - 如果自己的餐台空了，可以去其他餐台“偷”订单（Work Stealing）。

---

### **8. 总结：GMP 的优势**
| **特性**            | **说明**                                                                 |
|---------------------|-------------------------------------------------------------------------|
| **高并发**          | 轻松支持百万级 Goroutine。                                               |
| **低开销**          | 用户态调度，避免频繁的线程切换和锁竞争。                                  |
| **负载均衡**        | Work Stealing 机制自动平衡各 P 的任务。                                   |
| **高效系统调用**    | 阻塞时自动释放 P，由其他 M 继续执行任务。                                 |
| **抢占式调度**      | 防止单个 Goroutine 长时间占用 CPU。                                      |

---

### **9. 实际开发中的注意事项**
1. **设置 `GOMAXPROCS`**：通常设为 CPU 核数，但 I/O 密集型任务可适当增加。
2. **避免阻塞 Goroutine**：减少长时间阻塞操作，改用异步 I/O 或 `context` 超时控制。
3. **监控调度延迟**：使用 `go tool trace` 或 `pprof` 分析调度性能。

通过 GMP 模型，Go 在用户态实现了高效的协程调度，完美平衡了并发性能和资源消耗，这是 Go 成为高并发语言的核心原因。

Goroutine 特点：

- 占用内存更小（2KB左右，系统线程需要1-8MB）
- 调度更灵活（runtime 调度）

GM调度模型：

- G：Goroutine 的缩写，每次 go func() 都代表一个 G，无限制，但受内存影响。使用 struct runtime.g，包含了当前 goroutine 的状态、堆栈、上下文
- M：工作线程(OS thread)也被称为 Machine，使用 struct runtime.m，所有 M 是有线程栈的。M 的默认数量限制是 10000（来源），可以通过debug.SetMaxThreads修改。


![gm](https://blog.mineor.xyz/images/20231112/gm.jpg)

运行时刚启动时会启动一些G,其中一个负责垃圾回收，其中一个负责调度，其中一个负责用户的入口函数。一开始运行时只有一个M被创建，随后，用户层面的更多G被创建，然后更多的M被创建出来执行更多的G。同时最多同时支持GOMAXPROCS个活跃的线程。

M代表一个线程，M需要从全局G队列中取出一个G并且执行G对应的代码，如果G代码执行阻塞的系统调用，那么会首先从空闲的M队列中取出一个M唤醒，随后执行阻塞调用，陷入阻塞。这么做是因为线程阻塞后，活跃的线程数肯定就小于GOMAXPROCS了，这时我们就可以增加一个活跃的线程以防止当前有G在等在M。

造成阻塞的都是系统调用，在调用返回之前，线程会一直阻塞。但是注意，M不会在channel的操作中阻塞，这是因为操作系统并不知道channel，channel的所有的操作都是有运行时来处理的。所以如果goroutine执行了channel操作，这时goroutine可能会需要阻塞，但是这个阻塞不是操作系统带来的阻塞，因此M并不需要一起阻塞。这种场景下，这个G会被标记为waiting，然后原来执行这个G的M会继续去执行别的G。waiting的G在channel操作完成后会设为runable状态，并把自己放回到原来那个q的队列下，等待空闲的M来执行，不一定是先前那个M了。为了完成g的唤醒，waitting的这个g必然会在wating前先找个地方某个字段某个数组保存。


M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。

### 老调度器有几个缺点：

- 单一全局互斥锁(Sched.Lock)和集中状态存储。导致所有 goroutine 相关操作，比如：创建、结束、重新调度等都要上锁。
- Goroutine 传递问题。M 经常在 M 之间传递”可运行”的 goroutine，这导致调度延迟增大以及额外的性能损耗（刚创建的 G 放到了全局队列，而不是本地 M 执行，不必要的开销和延迟）
- 每一个M现在都持有一个内存，包括了阻塞状态的M也是持有的。Active状态的M跟总的M个数之比可以达到1:100。这就导致了过多的内存消耗，以及较差的数据局部性。数据局部性怎么理解呢？数据局部性这里是指G当前在M运行后对M的内存进行了预热，后面如果再次调度到同一个M那么可以加速访问，可想而知，因为现在G调度到同一个M的概率不高，所以数据局部性不好。
- 严重的线程阻塞/解锁。在系统调用的情况下，工作线程经常被阻塞和取消阻塞，这增加了很多开销。比如 M 找不到G，此时 M 就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的 G 来执行。

GM模型存在的问题在：Dmitry Vyukov “Scalable Go Scheduler Design Doc”有详细描述，推荐阅读

## 新调度器

### 调度器细节

Dmitry Vyukov的方案是引入一个结构P，用来模拟处理器，M依旧表示操作系统线程，G依旧表示一个goroutine。

GOMAXPROCS用来控制P的个数，同时P作为M执行G代码时的必需资源。

新的P结构会带走原来的M和SCHED结构中的一些属性，比如MCache从M移到了P，而G队列也被分成两类，SCHED结构保留全局G队列，同时每个P中都会有一个本地的G队列。

![newGmp](https://blog.mineor.xyz/images/20231112/newGmp.jpg)

P的本地队列可以解决旧调度器中单一全局锁的问题。注意P的本地G队列还是可能面临一个并发访问的场景，比如下面讲到的窃取算法。为了避免加锁，这里P的本地队列是一个LockFree的队列，窃取G时使用CAS原子操作来完成。关于LockFree和CAS的知识参见[Lock-Free](https://yizhi.ren/2017/09/19/reorder/)。

### 调用过程

1. 创建一个G对象
2. 如果还有空闲的的P，创建一个M
3. M会启动一个底层线程，循环执行能找到的G
4. G的执行顺序是先从本地队列找，本地没找到从全局队列找。一次性转移(全局G个数/P个数）个，再去其它P中找（窃取算法（stealing algorithm）)
5. 当P执行系统调用即将阻塞时，M会释放P，并进入阻塞，直到系统调用返回时，M会尝试获取空闲的P，有的话继续执行，没有就把G会放到全局G，而M会进入空闲的M队列。
以上的G任务是按照队列顺序执行（也就是go函数的调用顺序）。
另外在启动时会有一个专门的sysmon来监控和管理，记录所有P的G任务计数schedtick。如果某个P的schedtick一直没有递增，说明这个P一直在执行一个G任务，如果超过一定时间就会为G增加标记，并且该G执行非内联函数时中断自己并把自己加到队尾。

### 新调度器中引入了线程自旋

自旋有好处有坏处，好处是避免线程被阻塞陷入内核，坏处是自旋属于空转，浪费CPU。只能说适度使用自旋是可以带来好处的。新方案在两个地方引入自旋：

1，M找不到P（目的是一有P释放就结合）

2，M找到了P但找不到G（目的是一有runable的G就执行）

